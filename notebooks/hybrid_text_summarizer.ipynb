{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Start"
      ],
      "metadata": {
        "id": "54SjDEkNTjcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy gensim scikit-learn numpy networkx sumy pyLDAvis rouge-score datasets\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MeD0tKaTlqH",
        "outputId": "0c8fe4da-e1af-4c87-b68b-41139f025ff7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.12/dist-packages (3.4.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.12/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.14.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.12/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Load CNN/DailyMail dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "# Create development sample\n",
        "def create_development_sample(dataset, sample_size=50):\n",
        "    train_sample = dataset['train'].select(range(sample_size))\n",
        "    articles = train_sample['article']\n",
        "    highlights = train_sample['highlights']\n",
        "    ids = train_sample['id']\n",
        "    return articles, highlights, ids\n",
        "\n",
        "# Create sample\n",
        "articles, highlights, ids = create_development_sample(dataset, 50)\n",
        "print(f\"Created development sample with {len(articles)} articles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h6IA2EvTqIn",
        "outputId": "d011847b-3d63-424d-e75a-c92f5eb6ca09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created development sample with 50 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "class RobustTextPreprocessor:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.stop_words = set(stopwords.words('english'))\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "        except:\n",
        "            self.stop_words = set()\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        if not isinstance(text, str):\n",
        "            return \"\"\n",
        "        try:\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "            text = re.sub(r'[^a-zA-Z\\s\\.\\!\\?]', '', text)\n",
        "            text = text.lower()\n",
        "            return text.strip()\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "    def preprocess_sentence(self, sentence):\n",
        "        try:\n",
        "            cleaned = self.clean_text(sentence)\n",
        "            if not cleaned:\n",
        "                return \"\"\n",
        "            words = cleaned.split()\n",
        "            words = [self.lemmatizer.lemmatize(word) for word in words\n",
        "                    if word not in self.stop_words and len(word) > 2]\n",
        "            return ' '.join(words)\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "    def prepare_single_article(self, article, summary):\n",
        "        try:\n",
        "            original_sentences = sent_tokenize(article)\n",
        "            preprocessed_sentences = []\n",
        "            valid_original_sentences = []\n",
        "\n",
        "            for sent in original_sentences:\n",
        "                processed_sent = self.preprocess_sentence(sent)\n",
        "                if processed_sent and len(processed_sent.split()) >= 3:\n",
        "                    preprocessed_sentences.append(processed_sent)\n",
        "                    valid_original_sentences.append(sent)\n",
        "\n",
        "            if len(valid_original_sentences) >= 3:\n",
        "                return {\n",
        "                    'original_sentences': valid_original_sentences,\n",
        "                    'preprocessed_sentences': preprocessed_sentences,\n",
        "                    'reference_summary': summary,\n",
        "                    'num_sentences': len(valid_original_sentences)\n",
        "                }\n",
        "            else:\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing article: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize preprocessor and process data\n",
        "preprocessor = RobustTextPreprocessor()\n",
        "processed_data = []\n",
        "\n",
        "for i, (article, highlight) in enumerate(zip(articles, highlights)):\n",
        "    result = preprocessor.prepare_single_article(article, highlight)\n",
        "    if result:\n",
        "        result['id'] = ids[i]\n",
        "        processed_data.append(result)\n",
        "\n",
        "print(f\"Successfully processed {len(processed_data)} out of {len(articles)} articles\")\n",
        "if processed_data:\n",
        "    print(f\"First article has {processed_data[0]['num_sentences']} sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Eqirm9UFFe",
        "outputId": "fe20f0a6-0b3a-4ba2-968e-81ca959f6435"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully processed 50 out of 50 articles\n",
            "First article has 22 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim import corpora, models\n",
        "import networkx as nx\n",
        "\n",
        "class RobustHybridSummarizer:\n",
        "    def __init__(self, summary_ratio=0.3):\n",
        "        self.summary_ratio = summary_ratio\n",
        "        self.vectorizer = TfidfVectorizer(max_features=2000, min_df=1, max_df=0.8)\n",
        "\n",
        "    def get_sentence_vectors(self, preprocessed_sentences):\n",
        "        if len(preprocessed_sentences) < 2:\n",
        "            return np.ones((len(preprocessed_sentences), 10))\n",
        "        try:\n",
        "            vectors = self.vectorizer.fit_transform(preprocessed_sentences).toarray()\n",
        "            return vectors\n",
        "        except:\n",
        "            return np.random.rand(len(preprocessed_sentences), 10)\n",
        "\n",
        "    def perform_kmeans(self, sentence_vectors, n_clusters=None):\n",
        "        if len(sentence_vectors) < 2:\n",
        "            return [0] * len(sentence_vectors)\n",
        "        if n_clusters is None:\n",
        "            n_clusters = max(2, min(5, int(np.sqrt(len(sentence_vectors)))))\n",
        "        if n_clusters >= len(sentence_vectors):\n",
        "            n_clusters = max(1, len(sentence_vectors) - 1)\n",
        "        try:\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(sentence_vectors)\n",
        "            return cluster_labels\n",
        "        except:\n",
        "            return [0] * len(sentence_vectors)\n",
        "\n",
        "    def perform_lda(self, preprocessed_sentences, num_topics=3):\n",
        "        if len(preprocessed_sentences) < 3:\n",
        "            return [-1] * len(preprocessed_sentences), None\n",
        "        try:\n",
        "            tokenized_sentences = [sent.split() for sent in preprocessed_sentences]\n",
        "            tokenized_sentences = [tokens for tokens in tokenized_sentences if len(tokens) > 0]\n",
        "            if len(tokenized_sentences) < 2:\n",
        "                return [-1] * len(preprocessed_sentences), None\n",
        "            id2word = corpora.Dictionary(tokenized_sentences)\n",
        "            corpus = [id2word.doc2bow(tokens) for tokens in tokenized_sentences]\n",
        "            actual_topics = min(num_topics, len(tokenized_sentences) - 1)\n",
        "            if actual_topics < 1:\n",
        "                return [-1] * len(preprocessed_sentences), None\n",
        "            lda_model = models.LdaModel(\n",
        "                corpus=corpus,\n",
        "                id2word=id2word,\n",
        "                num_topics=actual_topics,\n",
        "                random_state=42,\n",
        "                passes=5,\n",
        "                alpha='auto'\n",
        "            )\n",
        "            sentence_topics = []\n",
        "            for i, bow in enumerate(corpus):\n",
        "                try:\n",
        "                    topic_scores = lda_model.get_document_topics(bow)\n",
        "                    if topic_scores:\n",
        "                        dominant_topic = max(topic_scores, key=lambda x: x[1])[0]\n",
        "                        sentence_topics.append(dominant_topic)\n",
        "                    else:\n",
        "                        sentence_topics.append(-1)\n",
        "                except:\n",
        "                    sentence_topics.append(-1)\n",
        "            while len(sentence_topics) < len(preprocessed_sentences):\n",
        "                sentence_topics.append(-1)\n",
        "            return sentence_topics, lda_model\n",
        "        except Exception as e:\n",
        "            print(f\"LDA Error: {e}\")\n",
        "            return [-1] * len(preprocessed_sentences), None\n",
        "\n",
        "    def perform_textrank(self, sentence_vectors):\n",
        "        if len(sentence_vectors) <= 1:\n",
        "            return [1.0] * len(sentence_vectors)\n",
        "        try:\n",
        "            similarity_matrix = cosine_similarity(sentence_vectors)\n",
        "            similarity_matrix = np.maximum(similarity_matrix, 0)\n",
        "            nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "            scores = nx.pagerank(nx_graph)\n",
        "            textrank_scores = [scores[i] for i in range(len(sentence_vectors))]\n",
        "            return textrank_scores\n",
        "        except:\n",
        "            return [1.0] * len(sentence_vectors)\n",
        "\n",
        "    def summarize(self, original_sentences, preprocessed_sentences):\n",
        "        if len(original_sentences) <= 2:\n",
        "            return ' '.join(original_sentences)\n",
        "        try:\n",
        "            sentence_vectors = self.get_sentence_vectors(preprocessed_sentences)\n",
        "            cluster_labels = self.perform_kmeans(sentence_vectors)\n",
        "            topic_assignments, _ = self.perform_lda(preprocessed_sentences)\n",
        "            textrank_scores = self.perform_textrank(sentence_vectors)\n",
        "\n",
        "            if textrank_scores and max(textrank_scores) > min(textrank_scores):\n",
        "                textrank_scores_norm = (textrank_scores - np.min(textrank_scores)) / \\\n",
        "                                     (np.max(textrank_scores) - np.min(textrank_scores))\n",
        "            else:\n",
        "                textrank_scores_norm = [1.0] * len(original_sentences)\n",
        "\n",
        "            final_scores = []\n",
        "            for i in range(len(original_sentences)):\n",
        "                score = 0.6 * textrank_scores_norm[i]\n",
        "                if i < len(topic_assignments) and topic_assignments[i] != -1:\n",
        "                    score += 0.3\n",
        "                final_scores.append(score)\n",
        "\n",
        "            num_to_select = max(1, int(len(original_sentences) * self.summary_ratio))\n",
        "            selected_indices = []\n",
        "\n",
        "            cluster_best = {}\n",
        "            for i, cluster_id in enumerate(cluster_labels):\n",
        "                if cluster_id not in cluster_best or final_scores[i] > final_scores[cluster_best[cluster_id]]:\n",
        "                    cluster_best[cluster_id] = i\n",
        "            selected_indices.extend(cluster_best.values())\n",
        "\n",
        "            remaining_indices = set(range(len(original_sentences))) - set(selected_indices)\n",
        "            if remaining_indices and len(selected_indices) < num_to_select:\n",
        "                remaining_list = sorted(remaining_indices, key=lambda x: final_scores[x], reverse=True)\n",
        "                needed = num_to_select - len(selected_indices)\n",
        "                selected_indices.extend(remaining_list[:needed])\n",
        "\n",
        "            selected_indices.sort()\n",
        "            summary_sentences = [original_sentences[i] for i in selected_indices]\n",
        "            return ' '.join(summary_sentences)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Summarization error: {e}\")\n",
        "            num_fallback = max(1, int(len(original_sentences) * self.summary_ratio))\n",
        "            return ' '.join(original_sentences[:num_fallback])\n",
        "\n",
        "# Initialize the original summarizer\n",
        "summarizer = RobustHybridSummarizer(summary_ratio=0.3)\n",
        "print(\"Original hybrid summarizer initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POL7CChtUIjP",
        "outputId": "bae9494b-4fc3-431a-b2ca-a4294bed9556"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original hybrid summarizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== TESTING ORIGINAL HYBRID SUMMARIZER ===\\n\")\n",
        "\n",
        "# Test on the first 3 processed samples\n",
        "for i, sample in enumerate(processed_data[:3]):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"Original sentences: {sample['num_sentences']}\")\n",
        "\n",
        "    # Generate summary\n",
        "    summary = summarizer.summarize(\n",
        "        sample['original_sentences'],\n",
        "        sample['preprocessed_sentences']\n",
        "    )\n",
        "\n",
        "    print(\"Generated Summary:\")\n",
        "    print(summary[:200] + \"...\" if len(summary) > 200 else summary)\n",
        "    print(\"\\nReference Summary:\")\n",
        "    print(sample['reference_summary'])\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCXXfQs4ULrG",
        "outputId": "bc20abaf-8cc1-4571-dcdd-8b1e6c5dddc5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TESTING ORIGINAL HYBRID SUMMARIZER ===\n",
            "\n",
            "Sample 1:\n",
            "Original sentences: 22\n",
            "Generated Summary:\n",
            "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on ...\n",
            "\n",
            "Reference Summary:\n",
            "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
            "Young actor says he has no plans to fritter his cash away .\n",
            "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
            "================================================================================\n",
            "Sample 2:\n",
            "Original sentences: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary:\n",
            "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial....\n",
            "\n",
            "Reference Summary:\n",
            "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
            "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
            "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
            "Leifman says the system is unjust and he's fighting for change .\n",
            "================================================================================\n",
            "Sample 3:\n",
            "Original sentences: 45\n",
            "Generated Summary:\n",
            "MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just comp...\n",
            "\n",
            "Reference Summary:\n",
            "NEW: \"I thought I was going to die,\" driver says .\n",
            "Man says pickup truck was folded in half; he just has cut on face .\n",
            "Driver: \"I probably had a 30-, 35-foot free fall\"\n",
            "Minnesota bridge collapsed during rush hour Wednesday .\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_evaluate(processed_data, summarizer, num_samples=5):\n",
        "    \"\"\"Quick evaluation on a few samples\"\"\"\n",
        "    print(\"=== QUICK EVALUATION ===\\n\")\n",
        "\n",
        "    for i, sample in enumerate(processed_data[:num_samples]):\n",
        "        print(f\"Evaluation Sample {i+1}:\")\n",
        "\n",
        "        generated = summarizer.summarize(\n",
        "            sample['original_sentences'],\n",
        "            sample['preprocessed_sentences']\n",
        "        )\n",
        "\n",
        "        print(f\"Original sentences: {sample['num_sentences']}\")\n",
        "        print(f\"Generated length: {len(generated)} chars\")\n",
        "        print(f\"Reference length: {len(sample['reference_summary'])} chars\")\n",
        "        print(\"---\")\n",
        "\n",
        "    print(\"Evaluation completed!\")\n",
        "\n",
        "# Run quick evaluation\n",
        "quick_evaluate(processed_data, summarizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erwQWJBCUQ2_",
        "outputId": "80a23599-eb58-4854-e370-eab8d990dabd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== QUICK EVALUATION ===\n",
            "\n",
            "Evaluation Sample 1:\n",
            "Original sentences: 22\n",
            "Generated length: 1029 chars\n",
            "Reference length: 217 chars\n",
            "---\n",
            "Evaluation Sample 2:\n",
            "Original sentences: 40\n",
            "Generated length: 1596 chars\n",
            "Reference length: 281 chars\n",
            "---\n",
            "Evaluation Sample 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentences: 45\n",
            "Generated length: 1348 chars\n",
            "Reference length: 224 chars\n",
            "---\n",
            "Evaluation Sample 4:\n",
            "Original sentences: 23\n",
            "Generated length: 697 chars\n",
            "Reference length: 185 chars\n",
            "---\n",
            "Evaluation Sample 5:\n",
            "Original sentences: 45\n",
            "Generated length: 2005 chars\n",
            "Reference length: 273 chars\n",
            "---\n",
            "Evaluation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_with_rouge(processed_data, summarizer, num_samples=10):\n",
        "    \"\"\"Evaluate the summarizer using ROUGE metrics\"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    rouge1_scores = []\n",
        "    rouge2_scores = []\n",
        "    rougeL_scores = []\n",
        "\n",
        "    print(\"=== COMPREHENSIVE ROUGE EVALUATION ===\\n\")\n",
        "\n",
        "    for i, sample in enumerate(processed_data[:num_samples]):\n",
        "        if i % 5 == 0:\n",
        "            print(f\"Processing sample {i+1}...\")\n",
        "\n",
        "        generated_summary = summarizer.summarize(\n",
        "            sample['original_sentences'],\n",
        "            sample['preprocessed_sentences']\n",
        "        )\n",
        "\n",
        "        reference_summary = sample['reference_summary']\n",
        "        scores = scorer.score(reference_summary, generated_summary)\n",
        "\n",
        "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "    avg_rouge1 = np.mean(rouge1_scores)\n",
        "    avg_rouge2 = np.mean(rouge2_scores)\n",
        "    avg_rougeL = np.mean(rougeL_scores)\n",
        "\n",
        "    print(\"\\n=== FINAL RESULTS ===\")\n",
        "    print(f\"ROUGE-1 F1 Score: {avg_rouge1:.4f}\")\n",
        "    print(f\"ROUGE-2 F1 Score: {avg_rouge2:.4f}\")\n",
        "    print(f\"ROUGE-L F1 Score: {avg_rougeL:.4f}\")\n",
        "    print(f\"Evaluated on {len(rouge1_scores)} samples\")\n",
        "\n",
        "    return {\n",
        "        'rouge1': avg_rouge1,\n",
        "        'rouge2': avg_rouge2,\n",
        "        'rougeL': avg_rougeL,\n",
        "        'all_scores': {\n",
        "            'rouge1': rouge1_scores,\n",
        "            'rouge2': rouge2_scores,\n",
        "            'rougeL': rougeL_scores\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Evaluate original model\n",
        "print(\"Evaluating original model with ROUGE...\")\n",
        "original_results = evaluate_with_rouge(processed_data, summarizer, num_samples=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbzfLcRMUT7_",
        "outputId": "7988d741-b516-46da-be80-6e818f09d024"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating original model with ROUGE...\n",
            "=== COMPREHENSIVE ROUGE EVALUATION ===\n",
            "\n",
            "Processing sample 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sample 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL RESULTS ===\n",
            "ROUGE-1 F1 Score: 0.2034\n",
            "ROUGE-2 F1 Score: 0.0724\n",
            "ROUGE-L F1 Score: 0.1348\n",
            "Evaluated on 10 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedHybridSummarizer:\n",
        "    def __init__(self, summary_ratio=0.25):\n",
        "        self.summary_ratio = summary_ratio\n",
        "        self.vectorizer = TfidfVectorizer(max_features=3000, min_df=1, max_df=0.85, ngram_range=(1, 2))\n",
        "\n",
        "    def get_sentence_vectors(self, preprocessed_sentences):\n",
        "        if len(preprocessed_sentences) < 2:\n",
        "            return np.ones((len(preprocessed_sentences), 10))\n",
        "        try:\n",
        "            vectors = self.vectorizer.fit_transform(preprocessed_sentences).toarray()\n",
        "            return vectors\n",
        "        except:\n",
        "            return np.random.rand(len(preprocessed_sentences), 10)\n",
        "\n",
        "    def perform_kmeans(self, sentence_vectors, n_clusters=None):\n",
        "        if len(sentence_vectors) < 2:\n",
        "            return [0] * len(sentence_vectors)\n",
        "        if n_clusters is None:\n",
        "            n_clusters = max(2, min(8, int(len(sentence_vectors) ** 0.7)))\n",
        "        if n_clusters >= len(sentence_vectors):\n",
        "            n_clusters = max(1, len(sentence_vectors) - 1)\n",
        "        try:\n",
        "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)\n",
        "            cluster_labels = kmeans.fit_predict(sentence_vectors)\n",
        "            return cluster_labels\n",
        "        except:\n",
        "            return [0] * len(sentence_vectors)\n",
        "\n",
        "    def perform_lda(self, preprocessed_sentences, num_topics=4):\n",
        "        if len(preprocessed_sentences) < 4:\n",
        "            return [-1] * len(preprocessed_sentences), None\n",
        "        try:\n",
        "            tokenized_sentences = [sent.split() for sent in preprocessed_sentences]\n",
        "            tokenized_sentences = [tokens for tokens in tokenized_sentences if len(tokens) > 2]\n",
        "            if len(tokenized_sentences) < 3:\n",
        "                return [-1] * len(preprocessed_sentences), None\n",
        "            id2word = corpora.Dictionary(tokenized_sentences)\n",
        "            corpus = [id2word.doc2bow(tokens) for tokens in tokenized_sentences]\n",
        "            actual_topics = min(num_topics, len(tokenized_sentences) - 1)\n",
        "            if actual_topics < 1:\n",
        "                return [-1] * len(preprocessed_sentences), None\n",
        "            lda_model = models.LdaModel(\n",
        "                corpus=corpus,\n",
        "                id2word=id2word,\n",
        "                num_topics=actual_topics,\n",
        "                random_state=42,\n",
        "                passes=15,\n",
        "                alpha='auto',\n",
        "                per_word_topics=True\n",
        "            )\n",
        "            sentence_topics = []\n",
        "            for bow in corpus:\n",
        "                try:\n",
        "                    topic_scores = lda_model.get_document_topics(bow)\n",
        "                    if topic_scores:\n",
        "                        dominant_topic = max(topic_scores, key=lambda x: x[1])\n",
        "                        if dominant_topic[1] > 0.3:\n",
        "                            sentence_topics.append(dominant_topic[0])\n",
        "                        else:\n",
        "                            sentence_topics.append(-1)\n",
        "                    else:\n",
        "                        sentence_topics.append(-1)\n",
        "                except:\n",
        "                    sentence_topics.append(-1)\n",
        "            while len(sentence_topics) < len(preprocessed_sentences):\n",
        "                sentence_topics.append(-1)\n",
        "            return sentence_topics, lda_model\n",
        "        except Exception as e:\n",
        "            print(f\"LDA Error: {e}\")\n",
        "            return [-1] * len(preprocessed_sentences), None\n",
        "\n",
        "    def perform_textrank(self, sentence_vectors):\n",
        "        if len(sentence_vectors) <= 1:\n",
        "            return [1.0] * len(sentence_vectors)\n",
        "        try:\n",
        "            similarity_matrix = cosine_similarity(sentence_vectors)\n",
        "            similarity_matrix = np.maximum(similarity_matrix, 0)\n",
        "            nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "            scores = nx.pagerank(nx_graph, alpha=0.85)\n",
        "            textrank_scores = [scores[i] for i in range(len(sentence_vectors))]\n",
        "            return textrank_scores\n",
        "        except:\n",
        "            return [1.0] * len(sentence_vectors)\n",
        "\n",
        "    def summarize(self, original_sentences, preprocessed_sentences):\n",
        "        if len(original_sentences) <= 2:\n",
        "            return ' '.join(original_sentences[:1])\n",
        "        try:\n",
        "            sentence_vectors = self.get_sentence_vectors(preprocessed_sentences)\n",
        "            cluster_labels = self.perform_kmeans(sentence_vectors)\n",
        "            topic_assignments, _ = self.perform_lda(preprocessed_sentences)\n",
        "            textrank_scores = self.perform_textrank(sentence_vectors)\n",
        "\n",
        "            if textrank_scores and max(textrank_scores) > min(textrank_scores):\n",
        "                textrank_scores_norm = (textrank_scores - np.min(textrank_scores)) / \\\n",
        "                                     (np.max(textrank_scores) - np.min(textrank_scores))\n",
        "            else:\n",
        "                textrank_scores_norm = [0.5] * len(original_sentences)\n",
        "\n",
        "            final_scores = []\n",
        "            for i in range(len(original_sentences)):\n",
        "                base_score = 0.5 * textrank_scores_norm[i]\n",
        "                position_bias = max(0, 1 - (i / len(original_sentences))) * 0.2\n",
        "                base_score += position_bias\n",
        "                if i < len(topic_assignments) and topic_assignments[i] != -1:\n",
        "                    base_score += 0.3\n",
        "                sentence_len = len(original_sentences[i].split())\n",
        "                if 8 <= sentence_len <= 25:\n",
        "                    base_score += 0.1\n",
        "                final_scores.append(base_score)\n",
        "\n",
        "            num_to_select = max(1, min(5, int(len(original_sentences) * self.summary_ratio)))\n",
        "            selected_indices = []\n",
        "\n",
        "            cluster_best = {}\n",
        "            for i, cluster_id in enumerate(cluster_labels):\n",
        "                if cluster_id not in cluster_best or final_scores[i] > final_scores[cluster_best[cluster_id]]:\n",
        "                    cluster_best[cluster_id] = i\n",
        "            selected_indices.extend(cluster_best.values())\n",
        "\n",
        "            remaining_indices = set(range(len(original_sentences))) - set(selected_indices)\n",
        "            if remaining_indices and len(selected_indices) < num_to_select:\n",
        "                remaining_list = sorted(remaining_indices, key=lambda x: final_scores[x], reverse=True)\n",
        "                needed = num_to_select - len(selected_indices)\n",
        "                selected_indices.extend(remaining_list[:needed])\n",
        "\n",
        "            if not selected_indices:\n",
        "                selected_indices = [np.argmax(final_scores)] if final_scores else [0]\n",
        "\n",
        "            selected_indices.sort()\n",
        "            summary_sentences = [original_sentences[i] for i in selected_indices]\n",
        "            return ' '.join(summary_sentences)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Summarization error: {e}\")\n",
        "            return original_sentences[0] if original_sentences else \"\"\n",
        "\n",
        "# Initialize improved summarizer\n",
        "improved_summarizer = ImprovedHybridSummarizer(summary_ratio=0.25)\n",
        "print(\"Improved hybrid summarizer initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pohg-XnUaIX",
        "outputId": "f25a264a-dedf-4753-b16a-abc1dde692c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved hybrid summarizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== COMPARING ORIGINAL vs IMPROVED MODEL ===\\n\")\n",
        "\n",
        "# Test on same samples for comparison\n",
        "for i, sample in enumerate(processed_data[:2]):\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(f\"Original sentences: {sample['num_sentences']}\")\n",
        "\n",
        "    # Original model\n",
        "    original_summary = summarizer.summarize(\n",
        "        sample['original_sentences'],\n",
        "        sample['preprocessed_sentences']\n",
        "    )\n",
        "\n",
        "    # Improved model\n",
        "    improved_summary = improved_summarizer.summarize(\n",
        "        sample['original_sentences'],\n",
        "        sample['preprocessed_sentences']\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- ORIGINAL MODEL SUMMARY ---\")\n",
        "    print(original_summary[:300] + \"...\" if len(original_summary) > 300 else original_summary)\n",
        "\n",
        "    print(\"\\n--- IMPROVED MODEL SUMMARY ---\")\n",
        "    print(improved_summary[:300] + \"...\" if len(improved_summary) > 300 else improved_summary)\n",
        "\n",
        "    print(\"\\n--- REFERENCE SUMMARY ---\")\n",
        "    print(sample['reference_summary'])\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "# Evaluate improved model\n",
        "print(\"\\nEvaluating improved model...\")\n",
        "improved_results = evaluate_with_rouge(processed_data, improved_summarizer, num_samples=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMcCunqXUe-I",
        "outputId": "007a00a8-b8a8-4507-c57f-1099640b1c15"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== COMPARING ORIGINAL vs IMPROVED MODEL ===\n",
            "\n",
            "\n",
            "Sample 1:\n",
            "Original sentences: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ORIGINAL MODEL SUMMARY ---\n",
            "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappoi...\n",
            "\n",
            "--- IMPROVED MODEL SUMMARY ---\n",
            "Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon a...\n",
            "\n",
            "--- REFERENCE SUMMARY ---\n",
            "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
            "Young actor says he has no plans to fritter his cash away .\n",
            "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
            "================================================================================\n",
            "\n",
            "Sample 2:\n",
            "Original sentences: 40\n",
            "\n",
            "--- ORIGINAL MODEL SUMMARY ---\n",
            "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the...\n",
            "\n",
            "--- IMPROVED MODEL SUMMARY ---\n",
            "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, an...\n",
            "\n",
            "--- REFERENCE SUMMARY ---\n",
            "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
            "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
            "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
            "Leifman says the system is unjust and he's fighting for change .\n",
            "================================================================================\n",
            "\n",
            "Evaluating improved model...\n",
            "=== COMPREHENSIVE ROUGE EVALUATION ===\n",
            "\n",
            "Processing sample 1...\n",
            "Processing sample 6...\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "ROUGE-1 F1 Score: 0.2287\n",
            "ROUGE-2 F1 Score: 0.0866\n",
            "ROUGE-L F1 Score: 0.1405\n",
            "Evaluated on 10 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_final_report(processed_data, original_summarizer, improved_summarizer, num_samples=15):\n",
        "    print(\"=\" * 80)\n",
        "    print(\"FINAL HYBRID SUMMARIZATION MODEL EVALUATION REPORT\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\n1. ROUGE SCORE COMPARISON\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    original_results = evaluate_with_rouge(processed_data, original_summarizer, num_samples)\n",
        "    improved_results = evaluate_with_rouge(processed_data, improved_summarizer, num_samples)\n",
        "\n",
        "    print(\"\\n2. SAMPLE OUTPUT ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for i, sample in enumerate(processed_data[:2]):\n",
        "        print(f\"\\nSample {i+1} Analysis:\")\n",
        "        print(f\"Original article sentences: {sample['num_sentences']}\")\n",
        "\n",
        "        original_summary = original_summarizer.summarize(\n",
        "            sample['original_sentences'], sample['preprocessed_sentences'])\n",
        "        improved_summary = improved_summarizer.summarize(\n",
        "            sample['original_sentences'], sample['preprocessed_sentences'])\n",
        "\n",
        "        print(f\"Original model summary length: {len(original_summary)} chars\")\n",
        "        print(f\"Improved model summary length: {len(improved_summary)} chars\")\n",
        "        print(f\"Reference summary length: {len(sample['reference_summary'])} chars\")\n",
        "\n",
        "        original_compression = len(original_summary) / len(' '.join(sample['original_sentences']))\n",
        "        improved_compression = len(improved_summary) / len(' '.join(sample['original_sentences']))\n",
        "\n",
        "        print(f\"Original model compression: {original_compression:.2%}\")\n",
        "        print(f\"Improved model compression: {improved_compression:.2%}\")\n",
        "\n",
        "    print(\"\\n3. MODEL COMPARISON SUMMARY\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"{'Metric':<15} {'Original':<10} {'Improved':<10} {'Change':<10}\")\n",
        "    print(f\"{'ROUGE-1':<15} {original_results['rouge1']:.4f}    {improved_results['rouge1']:.4f}    {improved_results['rouge1'] - original_results['rouge1']:+.4f}\")\n",
        "    print(f\"{'ROUGE-2':<15} {original_results['rouge2']:.4f}    {improved_results['rouge2']:.4f}    {improved_results['rouge2'] - original_results['rouge2']:+.4f}\")\n",
        "    print(f\"{'ROUGE-L':<15} {original_results['rougeL']:.4f}    {improved_results['rougeL']:.4f}    {improved_results['rougeL'] - original_results['rougeL']:+.4f}\")\n",
        "\n",
        "    return {\n",
        "        'original': original_results,\n",
        "        'improved': improved_results\n",
        "    }\n",
        "\n",
        "# Generate final report\n",
        "final_report = create_final_report(processed_data, summarizer, improved_summarizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42yVhpuGUkPG",
        "outputId": "cec2ee2a-6844-40cb-a80f-2bbd60919419"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FINAL HYBRID SUMMARIZATION MODEL EVALUATION REPORT\n",
            "================================================================================\n",
            "\n",
            "1. ROUGE SCORE COMPARISON\n",
            "----------------------------------------\n",
            "=== COMPREHENSIVE ROUGE EVALUATION ===\n",
            "\n",
            "Processing sample 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sample 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sample 11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL RESULTS ===\n",
            "ROUGE-1 F1 Score: 0.2141\n",
            "ROUGE-2 F1 Score: 0.0712\n",
            "ROUGE-L F1 Score: 0.1399\n",
            "Evaluated on 15 samples\n",
            "=== COMPREHENSIVE ROUGE EVALUATION ===\n",
            "\n",
            "Processing sample 1...\n",
            "Processing sample 6...\n",
            "Processing sample 11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL RESULTS ===\n",
            "ROUGE-1 F1 Score: 0.2295\n",
            "ROUGE-2 F1 Score: 0.0795\n",
            "ROUGE-L F1 Score: 0.1424\n",
            "Evaluated on 15 samples\n",
            "\n",
            "2. SAMPLE OUTPUT ANALYSIS\n",
            "----------------------------------------\n",
            "\n",
            "Sample 1 Analysis:\n",
            "Original article sentences: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model summary length: 1029 chars\n",
            "Improved model summary length: 996 chars\n",
            "Reference summary length: 217 chars\n",
            "Original model compression: 41.48%\n",
            "Improved model compression: 40.15%\n",
            "\n",
            "Sample 2 Analysis:\n",
            "Original article sentences: 40\n",
            "Original model summary length: 1596 chars\n",
            "Improved model summary length: 912 chars\n",
            "Reference summary length: 281 chars\n",
            "Original model compression: 40.43%\n",
            "Improved model compression: 23.10%\n",
            "\n",
            "3. MODEL COMPARISON SUMMARY\n",
            "----------------------------------------\n",
            "Metric          Original   Improved   Change    \n",
            "ROUGE-1         0.2141    0.2295    +0.0154\n",
            "ROUGE-2         0.0712    0.0795    +0.0083\n",
            "ROUGE-L         0.1399    0.1424    +0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def save_model_and_results(summarizer, processed_data, results, model_name=\"hybrid_summarizer\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save model\n",
        "    model_filename = f\"{model_name}_{timestamp}.pkl\"\n",
        "    with open(model_filename, 'wb') as f:\n",
        "        pickle.dump(summarizer, f)\n",
        "\n",
        "    # Save results\n",
        "    results_filename = f\"evaluation_results_{timestamp}.json\"\n",
        "    with open(results_filename, 'w') as f:\n",
        "        json.dump({\n",
        "            'timestamp': timestamp,\n",
        "            'model_name': model_name,\n",
        "            'results': results,\n",
        "            'dataset_info': {\n",
        "                'samples_processed': len(processed_data),\n",
        "                'average_sentences': np.mean([s['num_sentences'] for s in processed_data])\n",
        "            }\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"Model saved as: {model_filename}\")\n",
        "    print(f\"Results saved as: {results_filename}\")\n",
        "\n",
        "    return model_filename, results_filename\n",
        "\n",
        "# Save the improved model\n",
        "model_file, results_file = save_model_and_results(\n",
        "    improved_summarizer,\n",
        "    processed_data,\n",
        "    final_report['improved'],\n",
        "    \"improved_hybrid_summarizer\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== PROJECT COMPLETED SUCCESSFULLY ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCI-kHU9UnXH",
        "outputId": "8f6cdac2-5e4a-41d3-8238-249fc1656b64"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as: improved_hybrid_summarizer_20251019_071511.pkl\n",
            "Results saved as: evaluation_results_20251019_071511.json\n",
            "\n",
            "=== PROJECT COMPLETED SUCCESSFULLY ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# 1. Download your trained model\n",
        "with open('improved_hybrid_summarizer.pkl', 'wb') as f:\n",
        "    pickle.dump(improved_summarizer, f)\n",
        "files.download('improved_hybrid_summarizer.pkl')\n",
        "\n",
        "# 2. Download evaluation results\n",
        "results = {\n",
        "    \"rouge1\": 0.2295,\n",
        "    \"rouge2\": 0.0795,\n",
        "    \"rougeL\": 0.1424,\n",
        "    \"dataset_info\": {\n",
        "        \"samples_processed\": 50,\n",
        "        \"average_sentences\": 30.26\n",
        "    }\n",
        "}\n",
        "with open('evaluation_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "files.download('evaluation_results.json')\n",
        "\n",
        "# 3. Download your Colab notebook\n",
        "# Go to File → Download → Download .ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vdbbnzp4fzTD",
        "outputId": "9a3f9638-8057-4623-ad35-f27a792b0fb9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe39800d-10d0-455d-9a9f-032aa8badb52\", \"improved_hybrid_summarizer.pkl\", 22851)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e00e042-67be-46bf-8490-1a3bf1cbb032\", \"evaluation_results.json\", 147)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
